{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Module in TF-Slim\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../images/tensorflow.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training a Deep Learning model inspecting the loss alone does not provide interpretable measure about how well the neural network is training. \n",
    "\n",
    "Instead we compute at regular intervals evaluations metrics to score the model performance based on the task we care about. \n",
    "\n",
    "**Computing model performance includes**\n",
    "\n",
    "- loading the (subset) data\n",
    "- performing inference\n",
    "- comparing the results to the ground truth\n",
    "- recording the evaluation scores\n",
    "- repeating periodically\n",
    "\n",
    "\n",
    "**Evaluation Metrics**\n",
    "\n",
    "- a metric is a performance measure\n",
    "- a metric is not a loss function (losses are directly optimized during training)\n",
    "- a metric is consistent with the task of the problem\n",
    "- for example, we may want to minimize cross-entropy, but our metrics of interest might be accuracy or F1 score\n",
    "- a metric is no necessarily differentiable, and therefore cannot be used as a loss\n",
    "\n",
    "<img src=\"../images/recall.png\" width=\"200\">\n",
    "\n",
    "**F1 score is the harmonic mean of precision and recall**\n",
    "\n",
    "$${\\displaystyle F_{1}=2\\cdot {\\frac {1}{{\\tfrac {1}{\\mathrm {recall} }}+{\\tfrac {1}{\\mathrm {precision} }}}}=2\\cdot {\\frac {\\mathrm {precision} \\cdot \\mathrm {recall} }{\\mathrm {precision} +\\mathrm {recall} }}}$$\n",
    "\n",
    "** TF-Slim Metrics Module**\n",
    "\n",
    "TF-Slim provides a set of metric operations that makes evaluating models easy.\n",
    "Computing the value of a metric can be divided into three parts:\n",
    "\n",
    "Each metric function adds nodes to the graph that hold the state necessary to compute the value of the metric as well as a set of operations that actually perform the computation. Every metric evaluation is composed of three steps:\n",
    "\n",
    "1. **Initialization** - initialize the variables used to compute the metrics.\n",
    "2. **Aggregation** - updating the values of the metric state.\n",
    "3. **Finalization** - computing the final metric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append(\"../\") \n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Metrics\n",
    "\n",
    "TF-Slim provides a number of streaming metrics. These metrics are computed on dynamically valued Tensors, as sample batches are evaluated.\n",
    "\n",
    "Each metric declaration returns:\n",
    "\n",
    "- a **value_tensor** - an operation that returns the current value of the metric.\n",
    "- an **update_op** - an operation that accumulates the information from the current value of the batch of Tensors being measured.\n",
    "\n",
    "\n",
    "## Streaming Mean Metric\n",
    "Simple example on how a streaming mean would be computed.\n",
    "\n",
    "1. declare the metric\n",
    "2. call update_op repeatedly to accumulate data.\n",
    "3. evaluate the value_tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value = ...\n",
    "mean_value, update_op = slim.metrics.streaming_mean(values)\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "for i in range(number_of_batches):\n",
    "    print('Mean after batch %d: %f' % (i, update_op.eval())\n",
    "print('Final Mean: %f' % mean_value.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Multiple Metrics\n",
    "\n",
    "In practice, we commonly want to evaluate multiple metrics at the same time. Below is how you would define three different metrics. Each metric generate it's own update operation that accumulates the results across multiple batches.\n",
    "\n",
    "For example, to compute mean_absolute_error, two variables, a count and total variable are initialized to zero. During aggregation, we observed some set of predictions and labels, compute their absolute differences and add the total to total variable. Each time we observe another value, the count variable is incremented. Finally, during finalization, total is divided by count to obtain the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "images, labels = LoadTestData(...)\n",
    "\n",
    "# make predictions\n",
    "predictions = MyModel(images)\n",
    "\n",
    "# Evaluation metrics\n",
    "mae_value_op, mae_update_op = slim.metrics.streaming_mean_absolute_error(predictions, labels)\n",
    "mre_value_op, mre_update_op = slim.metrics.streaming_mean_relative_error(predictions, labels, labels)\n",
    "pl_value_op, pl_update_op = slim.metrics.percentage_less(mean_relative_errors, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Aggregation\n",
    "\n",
    "Each metric returns a `value_op` and `update_op`. Keeping track of each of these operations can become difficult when there are a lot of metrics.\n",
    "\n",
    "**List Aggregation**\n",
    "\n",
    "To deal with this, TF-Slim provides an aggregate functions that combines them togther."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregates the value and update ops in two lists:\n",
    "value_ops, update_ops = slim.metrics.aggregate_metrics(\n",
    "    slim.metrics.streaming_mean_absolute_error(predictions, labels),\n",
    "    slim.metrics.streaming_mean_squared_error(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary Aggregation**\n",
    "\n",
    "We can also aggregate metrics into a dictionary and give each one of them names.\n",
    "In practice, we commonly want to evaluate across many batches and multiple metrics.\n",
    "This is done by run the aggregate metric computation operations multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "images, labels = load_data(...)\n",
    "\n",
    "# Define a neural network\n",
    "logits = MyModel(images)\n",
    "predictions = tf.argmax(logits, 1)\n",
    "\n",
    "\n",
    "# Aggregates the value and update ops in two dictionaries:\n",
    "names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n",
    "    'eval/Accuracy': slim.metrics.streaming_accuracy(predictions, targets),\n",
    "    'eval/Recall@3': slim.metrics.streaming_recall_at_k(tf.to_float(logits), targets, 3),\n",
    "    'eval/Precision': slim.metrics.streaming_precision(predictions, targets),\n",
    "    'eval/Recall': slim.metrics.streaming_recall(predictions, targets)\n",
    "})\n",
    "\n",
    "\n",
    "# Evaluate the model using 1000 batches of data:\n",
    "num_batches = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    # run metrics over multiple batches\n",
    "    for batch_id in range(num_batches):\n",
    "        sess.run(names_to_updates.values())\n",
    "\n",
    "    # Get each metric end value\n",
    "    metric_values = sess.run(name_to_values.values())\n",
    "    for metric, value in zip(names_to_values.keys(), metric_values):\n",
    "        print('Metric %s has value: %f' % (metric, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Other Functions Provided by Slim.metrics Module\n",
    "\n",
    "TF-Slim provides other useful metric function and distance metrics that I will let you explore on your own. Below are a few examples:\n",
    "\n",
    "```\n",
    "slim.metrics.streaming_recall_at_k\n",
    "slim.metrics.confusion_matrix\n",
    "slim.metrics.streaming_auc\n",
    "slim.metrics.streaming_mean_cosine_distance\n",
    "slim.metrics.streaming_root_mean_squared_error\n",
    "slim.metrics.streaming_pearson_correlation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next Lesson\n",
    "### Compact Evaluation Routings in TF-Slim\n",
    "-  Construct evaluation routines and score the performance of your deep neural network.\n",
    "\n",
    "<img src=\"../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-latest]",
   "language": "python",
   "name": "conda-env-TF-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
