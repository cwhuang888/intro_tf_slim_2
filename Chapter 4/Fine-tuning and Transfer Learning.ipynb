{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning and Transfer Learning in TF-Slim\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../images/tensorflow.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append(\"../\") \n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Existing Models\n",
    "\n",
    "## Restoring Variables from a Checkpoint\n",
    "\n",
    "After a model has been trained, it can be restored using tf.train.Saver() which restores Variables from a given checkpoint. tf.train.Saver() provides a simple mechanism to restore all or just a few variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some variables.\n",
    "v1 = tf.Variable(..., name=\"v1\")\n",
    "v2 = tf.Variable(..., name=\"v2\")\n",
    "\n",
    "# Add ops to restore all the variables.\n",
    "restorer = tf.train.Saver()\n",
    "\n",
    "# Add ops to restore some variables.\n",
    "restorer = tf.train.Saver([v1, v2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    restorer.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Variables restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a Model From a Checkpoint\n",
    "\n",
    "It is common to want to 'warm-start' a model from a pre-trained checkpoint. For example, the training process was paused and  we wish to resume training. Or we wish to restore the model from a crash.\n",
    "\n",
    "TF-Slim provides a convenient mechanism for doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the train_op\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "\n",
    "# Create the initial assignment op\n",
    "checkpoint_path = '/path/to/old_model_checkpoint'\n",
    "\n",
    "# get all the variable from the model\n",
    "variables_to_restore = slim.get_model_variables()\n",
    "\n",
    "# Load and restore all the variables from the model\n",
    "init_assign_op, init_feed_dict = slim.assign_from_checkpoint(\n",
    "    checkpoint_path, variables_to_restore)\n",
    "\n",
    "# Create an initial assignment function.\n",
    "def InitAssignFn(sess):\n",
    "    sess.run(init_assign_op, init_feed_dict)\n",
    "    \n",
    "# Runs a training loop\n",
    "slim.learning.train(train_op, my_log_dir, init_fn=InitAssignFn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Part of a Model from Checkpoint \n",
    "\n",
    "\n",
    "Rather than initializing all of the weights of a given model, we sometimes\n",
    "only want to restore some of the weights from a checkpoint.\n",
    "\n",
    "**Partially Restoring Models**\n",
    "\n",
    "For example, it is common to fine-tune a pre-trained model on an entirely new dataset. In these situations, one can use TF-Slim's helper functions to select a subset of variables to restore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify the variables to restore via a list of inclusion or exclusion\n",
    "# Keep all the convolutional layers and remove the fully connected ones\n",
    "variables_to_restore = slim.get_variables_to_restore(\n",
    "    include=[\"conv\"], exclude=[\"fc8\", \"fc9\"])\n",
    "\n",
    "# or this is equivalent\n",
    "variables_to_restore = slim.get_variables_to_restore(include=[\"conv\"])\n",
    "\n",
    "# or by variable name\n",
    "variables_to_restore = slim.get_variables_by_name(\"conv2\")\n",
    "\n",
    "# or by variable name suffix\n",
    "variables_to_restore = slim.get_variables_by_suffix(\"2\")\n",
    "\n",
    "# or by variable scope\n",
    "variables_to_restore = slim.get_variables(scope=\"conv-scope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning on a Different Task\n",
    "\n",
    "\n",
    "<img src=\"../images/transfer_learning.jpg\" width=\"400\">\n",
    "\n",
    "In practice, it is very time consuming to train an entire Convolutional Network from scratch, because it is relatively rare to have a dataset of sufficient size.\n",
    "\n",
    "Instead, people use pre-trained models trained on a large datasets. For example, ImageNet, which contains 1.2 million images with 1000 categories).\n",
    "\n",
    "Your new task most likely won't have excatly the same number of categories to classify over, than the pre-trained model. In practice, only the convolutional layers are kept and the fully connected layers are re-initialized to random vectors.\n",
    "\n",
    "There are two main Transfer Learning schemes\n",
    "\n",
    "1. Convolutional layers as **fixed feature extractor**\n",
    "\n",
    "        This scheme treats the Convolutional layers as a fixed feature extractor for the new dataset. Convolutional layers have fixed weights and therefore are not trained. They are used to extract features and construct a rich vector embedding for every image. Once these embeddings have been computed for all images, they become the new inputs and can be used to train a linear classifier (e.g. Linear SVM or Softmax classifier) for the new dataset.\n",
    "    \n",
    "\n",
    "2. **Fine-tuning** the Convolutional layers.\n",
    "\n",
    "        This scheme treats the Convolutional layers has part of the model and applies backpropagation through the all model.  This fine-tunes the weights of the pretrained network to the new task. It is also possible to keep some of the earlier layers fixed (due to overfitting concerns) and only fine-tune some higher-level portion of the network. Earlier features of a CNN contain more generic features (e.g. edge detectors or color blob detectors) that should be useful to many tasks. However, later layers becomes progressively more specific and therefore may not be appropriate for the new task.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load other dataset\n",
    "images, labels = DataLoader(...)\n",
    "\n",
    "# Create the model\n",
    "predictions = ModelNewTask(images)\n",
    "\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "\n",
    "# Specify where the Model, trained on ImageNet, was saved.\n",
    "model_path = '/path/to/pre_trained_on_imagenet.checkpoint'\n",
    "\n",
    "# Specify where the new model will be stored:\n",
    "log_dir = '/path/to/newl_model_dir/'\n",
    "\n",
    "# Restore only the convolutional layers:\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude=['fc6', 'fc7', 'fc8'])\n",
    "\n",
    "# restore selected variables from checkpoints\n",
    "init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "\n",
    "# Runs a training loop using a TensorFlow supervisor.\n",
    "slim.learning.train(train_op, log_dir, init_fn=init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### TensorBoard - Visualize Neural Networks and Inspect Model Learning\n",
    "-  Use TensorBoard to visualize the network computational graph, as well as, inspecting and understanding the model's training progress.\n",
    "\n",
    "<img src=\"../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TFr12-py2-env]",
   "language": "python",
   "name": "conda-env-TFr12-py2-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
